####################################################################
# Sample Logstash v1.5.x Configuration for Oracle WebLogic App Server 12c
#
# Web: http://www.oracle.com/technetwork/middleware/weblogic/overview/index.html
# Community: http://www.oracle.com/technetwork/middleware/weblogic/community/index.html
# Docs: http://www.oracle.com/technetwork/middleware/weblogic/documentation/index.html
# Log Info: http://docs.oracle.com/middleware/1213/wls/WLLOG/logging_services.htm#WLLOG130
#
####################################################################
# v1.0 Doug McClure 9/23/15 Oracle WebLogic App Server 12c - access log and error log
#
####################################################################

input {

#############################################################################################
#Oracle WebLogic App Server Logs
#############################################################################################

#file inputs used as I was provided sample logfiles. In a live streaming environment other inputs like TCP would be used here.

#access.log, access.logNUMBER
file {
		path => "/opt/scala/driver/Logstash/ORACLE-WEBLOGIC-AS/oracle_weblogic_app_server_logs/foobar1/access*"
		#this forces the entire logfile to be read from beginning. Creates tracking state file in $HOME directory as .sincedb.... (delete to reprocess log)
		start_position => "beginning"
		type => "ORACLE-WEBLOGIC-AS"
		tags => ["access_log"]
	}	

#foobar1.log, foobar1.logNUMBER	
file {
		path => "/opt/scala/driver/Logstash/ORACLE-WEBLOGIC-AS/oracle_weblogic_app_server_logs/foobar1/foobar1*"
		#this forces the entire logfile to be read from beginning. Creates tracking state file in $HOME directory as .sincedb.... (delete to reprocess log)
		start_position => "beginning"
		exclude => "*out*"
		type => "ORACLE-WEBLOGIC-AS"
		tags => ["error_log"]
	}	

#foobar1.out, foobar1.outNUMBER
file {
		path => "/opt/scala/driver/Logstash/ORACLE-WEBLOGIC-AS/oracle_weblogic_app_server_logs/foobar1/foobar1*"
		#this forces the entire logfile to be read from beginning. Creates tracking state file in $HOME directory as .sincedb.... (delete to reprocess log)
		start_position => "beginning"
		exclude => "*log*"
		type => "ORACLE-WEBLOGIC-AS"
		tags => ["output_log"]
	}		
	
##########################################################################

} #end input

##########################################################################

filter {

#common stuff for all logs

#copy orig filepath to new fields

	mutate {
		add_field => { "origFilePath" => "%{path}" }
		add_tag => [ "origFilePathCreated" ]
	} #end mutate

#parse hostname and logfile name from new filepath field and create new hostname and logfile fields
#add add' patterns for other directories as needed

	grok {
		match => {"origFilePath" => "oracle_weblogic_app_server_logs/%{DATA:hostname}/%{GREEDYDATA:logfile}"}
		add_tag => [ "hostnameLogfileCreated" ]
	} #end grok
	
############################################################
# ORACLE-WEBLOGIC-AS
############################################################
	
if [type] == "ORACLE-WEBLOGIC-AS" and "hostnameLogfileCreated" in [tags] {

	if "access_log" in [tags] {
		
		#extract useful fields based on patterns seen in sample logs provided
		
		grok {
			match => {"message" => "%{ORAWEBLOGICACCESS}"}
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			add_tag => [ "ORACLE-WebLogic-access_log-Grokked" ]
		} #end grok
		
		#fix sessions where bytes is '-' so we don't get a datatype error in LA
		
		if [bytes] == "-" {
			mutate {
				replace => { "bytes" => "0" }
			} #end mutate
		} #end conditional
		
		#normalize date format to ISO8601
		#22/Sep/2015:12:50:28 -0700
		
		date {
			match => [ "origTimestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
			target => "@timestamp"
			add_tag => [ "timestamp-fixed" ]
		} #end date
		
		#set the host/path value for the LA datasource.  This is set for consolidation of all logs to functional datasources in LA.
		
		mutate {
			#replace => [ "host", "%{hostname}", "path", "%{type}-access_log" ]
			replace => [ "host", "access_log", "path", "%{type}" ]
			add_tag => [ "ORACLE-WebLogic-Final" ]
		} #end mutate
		
	} #end access_log conditional
	
	if "error_log" in [tags] {
		
		#this fixes multiline log messages like stack traces which were found in log samples
		
		multiline {
			pattern => "^####"
			negate => "true"
			what => "previous"
		} #end multi
		
		#extract useful fields based on patterns seen in sample logs provided
		
		grok {
			match => {"message" => "%{ORAWEBLOGICERR}"}
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			add_tag => [ "ORACLE-WebLogic-error_log-Grokked" ]
		} #end grok
		
		#normalize date format to ISO8601
		#Nov 8, 2014 1:28:52 PM MST
		
		date {
			match => [ "origTimestamp", "MMM dd, YYYY HH:mm:ss a z" ]
			target => "@timestamp"
			add_tag => [ "timestamp-fixed" ]
		} #end date
		
		#set the host/path value for the LA datasource.  This is set for consolidation of all logs to functional datasources in LA.
		
		mutate {
			#replace => [ "host", "%{hostname}", "path", "%{type}-error_log" ]
			replace => [ "host", "error_log", "path", "%{type}" ]
			add_tag => [ "ORACLE-WebLogic-Final" ]
		} #end mutate
		
	} #end error_log conditional
	
	if "output_log" in [tags] {
		
		#this fixes multiline log messages like stack traces which were found in log samples
		
		multiline {
			pattern => ["^<%{MONTH}"]
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			negate => "true"
			what => "previous"
		} #end multi
		
		#extract useful fields based on patterns seen in sample logs provided
		
		grok {
			match => {"message" => "%{ORAWEBLOGICOUT}"}
			match => {"message" => "%{ORAWEBLOGICOUT2}"}
			patterns_dir => ["/opt/scala/driver/Logstash/logstash-1.5.3/patterns"]
			add_tag => [ "ORACLE-WebLogic-output_log-Grokked" ]
		} #end grok
		
		#normalize date format to ISO8601
		#Sep 20, 2015 5:49:15 AM MST
		
		date {
			match => [ "origTimestamp", "MMM dd, YYYY HH:mm:ss a z", "MMM dd, YYYY HH:mm:ss a" ]
			target => "@timestamp"
			add_tag => [ "timestamp-fixed" ]
		} #end date
		
		#set the host/path value for the LA datasource.  This is set for consolidation of all logs to functional datasources in LA.
		
		mutate {
			#replace => [ "host", "%{hostname}", "path", "%{type}-output_log" ]
			replace => [ "host", "output_log", "path", "%{type}" ]
			add_tag => [ "ORACLE-WebLogic-Final" ]
		} #end mutate
		
	} #end output_log conditional
	
} #end ORACLE-WebLogic conditional
	

##########################################################################

} #end filter

##########################################################################

output {

if "ORACLE-WebLogic-Final" in [tags] {
	
	scala {
		scala_url => "https://10.0.0.1:9987/Unity/DataCollector"
		scala_user => "unityadmin"
		scala_password => "unityadmin"
		scala_keystore_path => ""
		batch_size => 500000
		idle_flush_time => 5
		sequential_flush => true
		num_concurrent_writers => 20
		use_structured_api => false
		disk_cache_path => "/opt/scala/driver/Logstash/cache-dir"
		scala_fields =>
		  {
			"access_log@ORACLE-WEBLOGIC-AS" => "@timestamp,hostname,logfile,clientip,ident,auth,verb,request,httpversion,response,bytes"
			"error_log@ORACLE-WEBLOGIC-AS" => "@timestamp,hostname,logfile,severity,subsystem,origHostname,serverName,threadID,userID,transactionID,diagContextID,rawTimeValue,messageID,origMessage"
			"output_log@ORACLE-WEBLOGIC-AS" => "@timestamp,hostname,logfile,severity,subsystem,messageID,origMessage"
		  }
		#the default timestamp format for string field @timestamp - may need to tweak to fit based on LA+logstash vesion you're using
		date_format_string => "yyyy-MM-dd'T'HH:mm:ssX"
		log_file => "/opt/scala/driver/Logstash/logs/scala_logstash.log"
		log_level => "info"
	} #end LA output
	
} #end LA output conditional	

###### DEBUGGING ###########

# show rubydebug in the console

stdout {
    codec => rubydebug
    } #end stdout
	
if "_grokparsefailure" in [tags] {
	file {
		message_format => "%{message}"
		path => "/opt/scala/driver/Logstash/logs/ORACLE-WEBLOGIC-AS/%{type}-%{hostname}-%{logfile}-grok-debug.log"
	} # end file 
} #end conditional

} #end output